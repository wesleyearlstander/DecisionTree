{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dataset = pd.read_csv(\"letter-recognition.data\",delimiter=',', header=None)\n",
    "dataset.columns = [\"lettr\", \"x-box\", \"y-box\", \"width-box\", \"height-box\", \"total pixels\", \"x-bar\", \"y-bar\", \"x2bar\", \"y2bar\", \"xybar\", \"x2ybr\", \"xy2br\", \"x-ege\", \"xegvy\", \"y-ege\", \"yegvx\"]\n",
    "dataset\n",
    "\n",
    "def entropy(target):\n",
    "    element,count = np.unique(target,return_counts=True)\n",
    "    entropy = np.sum([(-count[i]/np.sum(count))*np.log2(count[i]/np.sum(count)) for i in range(len(element))])\n",
    "    return entropy\n",
    "\n",
    "def InfoGain(data, attribute):\n",
    "    totalEntropy = entropy(data[\"lettr\"])\n",
    "    element,count=np.unique(data[attribute],return_counts=True)\n",
    "    weightedEntropy = np.sum([(count[i]/np.sum(count))*entropy(data.where(data[attribute]==element[i]).dropna()[\"lettr\"]) for i in range(len(element))])\n",
    "    return totalEntropy - weightedEntropy\n",
    "\n",
    "def testSplit(value, dataset, feature):\n",
    "    smaller, bigger = [], []\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row[feature] < value:\n",
    "            smaller.append(row)\n",
    "        else:\n",
    "            bigger.append(row)\n",
    "    smaller = pd.DataFrame(smaller)\n",
    "    bigger = pd.DataFrame(bigger)\n",
    "    return smaller, bigger\n",
    "\n",
    "def gini(dataGroups, targets):\n",
    "    groupsNo = float(sum([len(g) for g in dataGroups]))\n",
    "    giniO = 0\n",
    "    for g in dataGroups:\n",
    "        rows = len(g)\n",
    "        if rows == 0:\n",
    "            continue\n",
    "        score = 0\n",
    "        counts = g[\"lettr\"].value_counts(normalize=True)\n",
    "        for target in targets:\n",
    "            try:\n",
    "                a = counts[target]\n",
    "                score += a * a\n",
    "            except:\n",
    "                continue\n",
    "        giniO += (1-score) * (rows/groupsNo)\n",
    "    return giniO\n",
    "\n",
    "def getSplit(dataset, minSize):\n",
    "    ffeature, value, score, groupss = None, 999, 999, None\n",
    "    for feature in dataset.columns[1:]:\n",
    "        for row in dataset[feature].unique().tolist():\n",
    "            groups = testSplit(row, dataset, feature)\n",
    "            giniO = gini(groups, dataset[\"lettr\"].unique().tolist())\n",
    "            if giniO < score:\n",
    "                ffeature, value, score, groupss = feature, row, giniO, groups\n",
    "    return {'feature':ffeature, 'value':value, 'groups':groupss}\n",
    "\n",
    "def buildTree(trainingData, maxDepth,minSize, depth = 1):\n",
    "    root = getSplit(trainingData, minSize)\n",
    "    tree = {root[\"feature\"]:{}}\n",
    "    left, right = root['groups']\n",
    "    right = right.reset_index(drop=True)\n",
    "    left = left.reset_index(drop=True)\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        tree = np.unique(trainingData[\"lettr\"])[np.argmax(np.unique(trainingData[\"lettr\"],return_counts=True)[0])]\n",
    "        return tree\n",
    "    if depth >= maxDepth:\n",
    "        tree[root[\"feature\"]][\"L\" + str(root[\"value\"])] = np.unique(left[\"lettr\"])[np.argmax(np.unique(left[\"lettr\"],return_counts=True)[0])]\n",
    "        tree[root[\"feature\"]][\"B\" + str(root[\"value\"])] = np.unique(right[\"lettr\"])[np.argmax(np.unique(right[\"lettr\"],return_counts=True)[0])]\n",
    "        return tree\n",
    "    if len(left) <= minSize:\n",
    "        tree[root[\"feature\"]][\"L\" + str(root[\"value\"])] = np.unique(left[\"lettr\"])[np.argmax(np.unique(left[\"lettr\"],return_counts=True)[0])]\n",
    "    else:\n",
    "        tree[root[\"feature\"]][\"L\" + str(root[\"value\"])] = buildTree(left, maxDepth, minSize, depth+1)\n",
    "    if len(right) <= minSize:\n",
    "        tree[root[\"feature\"]][\"B\" + str(root[\"value\"])] = np.unique(right[\"lettr\"])[np.argmax(np.unique(right[\"lettr\"],return_counts=True)[0])]\n",
    "    else:\n",
    "        tree[root[\"feature\"]][\"B\" + str(root[\"value\"])] = buildTree(right, maxDepth, minSize, depth+1)\n",
    "    return tree\n",
    "\n",
    "def predictC (query,tree):\n",
    "    for key, value in query.items():\n",
    "        if key in tree.keys():\n",
    "            result = None\n",
    "            for key2 in tree[key].keys():\n",
    "                string = key2 #either B/L-number\n",
    "                number = float(string[1:]) # number\n",
    "                if string[0] == 'B':\n",
    "                    if value >= number:\n",
    "                        result = tree[key][key2]\n",
    "                else:\n",
    "                    if value < number:\n",
    "                        result = tree[key][key2]\n",
    "            if isinstance(result, dict):\n",
    "                return predictC(query, result)\n",
    "            else:\n",
    "                return result\n",
    "            \n",
    "def testC (data,tree):\n",
    "    queries = data.iloc[:,1:].to_dict(orient = \"records\")\n",
    "    \n",
    "    predicted = pd.DataFrame(columns=[\"lettr\"]) \n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"lettr\"] = predictC(queries[i],tree)\n",
    "    \n",
    "    finalPercent = np.sum(predicted[\"lettr\"]==data[\"lettr\"])/len(data)*100\n",
    "    print('accuracy = ',finalPercent,'%')\n",
    "    return finalPercent\n",
    "\n",
    "def testsC (data,trees):\n",
    "    queries = data.iloc[:,1:].to_dict(orient = \"records\")\n",
    "    percent = []\n",
    "    predictions = []\n",
    "    predicted = pd.DataFrame(columns=[\"lettr\"])\n",
    "    finalPredicted = pd.DataFrame(columns=[\"lettr\"])\n",
    "    default = np.unique(data[\"lettr\"])[np.argmax(np.unique(data[\"lettr\"],return_counts=True)[0])]\n",
    "    for k in range(len(trees)):\n",
    "        for i in range(len(data)):\n",
    "            predicted.loc[i,\"lettr\"] = predictC(queries[i],trees[k])\n",
    "        predictions.append(predicted.copy(deep=True))\n",
    "        percent.append(np.sum(predicted[\"lettr\"]==data[\"lettr\"])/len(data))\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"lettr\"] = vote(predictions, percent, i)\n",
    "    confusionMatrix = confusion_matrix(data[\"lettr\"], predicted[\"lettr\"])\n",
    "    print(confusionMatrix)\n",
    "    finalPercent = np.sum(predicted[\"lettr\"]==data[\"lettr\"])/len(data)*100\n",
    "    print('accuracy = ',finalPercent,'%')\n",
    "    return finalPercent, confusionMatrix\n",
    "\n",
    "def randomForestC (data, splits, maxDepth, minSize):\n",
    "    trees = []\n",
    "    splitData = dataSplit(data,splits)\n",
    "    for d in range(splits):\n",
    "        trees.append(buildTree(splitData[d], maxDepth, minSize))\n",
    "    return trees\n",
    "\n",
    "def ID3(data,originalData,features,parent=None):\n",
    "    if len(np.unique(data[\"lettr\"])) == 1:\n",
    "        return np.unique(data[\"lettr\"])[0]\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originalData[\"lettr\"])[np.argmax(np.unique(originalData[\"lettr\"],return_counts=True)[0])] #was 1\n",
    "    elif len(features) ==0:\n",
    "        return parent\n",
    "    else:\n",
    "        parent = np.unique(data[\"lettr\"])[np.argmax(np.unique(data[\"lettr\"],return_counts=True)[0])] #was 1\n",
    "        \n",
    "        items = [InfoGain(data,feature) for feature in features] \n",
    "        bestFeature = features[np.argmax(items)]\n",
    "        \n",
    "        tree = {bestFeature:{}}\n",
    "        \n",
    "        features = [i for i in features if i != bestFeature]\n",
    "        \n",
    "        for value in np.unique(data[bestFeature]):\n",
    "            subData = data.where(data[bestFeature] == value).dropna()\n",
    "            subTree = ID3(subData,originalData,features,parent)\n",
    "            tree[bestFeature][value] = subTree\n",
    "            \n",
    "        return (tree)\n",
    "\n",
    "def predict (query,tree):\n",
    "    default = modeOfBranch(tree)\n",
    "    for key in query.keys():\n",
    "        if key in tree.keys():  \n",
    "            try: \n",
    "                result = tree[key][query[key]]\n",
    "            except:\n",
    "                return default\n",
    "            result = tree[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "            else:\n",
    "                return result\n",
    "\n",
    "\n",
    "def dataSplit(dataset, splitsNo): \n",
    "    splits = []\n",
    "    for i in range(splitsNo):\n",
    "        fraction = 1/(splitsNo-i)\n",
    "        data = dataset.sample(frac=fraction)\n",
    "        dataset = dataset.drop(data.index)\n",
    "        data = data.reset_index(drop=True)\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        splits.append(data)\n",
    "    return splits\n",
    "\n",
    "def trainValidateTestSplit(dataset):\n",
    "    training_data = dataset.sample(frac=0.8)\n",
    "    testingValidation_data = dataset.drop(training_data.index)\n",
    "    #validation_data = testingValidation_data.sample(frac=0.5)\n",
    "    testing_data = testingValidation_data#.drop(validation_data.index)\n",
    "    training_data = training_data.reset_index(drop=True)\n",
    "    testing_data = testing_data.reset_index(drop=True)\n",
    "    #validation_data = validation_data.reset_index(drop=True)\n",
    "    return training_data,testing_data#,validation_data\n",
    "\n",
    "temp = trainValidateTestSplit(dataset)\n",
    "trainingData = temp[0]\n",
    "testingData = temp[1]\n",
    "#validationData = temp[2]\n",
    "\n",
    "def unique (l):\n",
    "    u = []\n",
    "    for x in l:\n",
    "        if x not in u:\n",
    "            u.append(x)\n",
    "    return u\n",
    "\n",
    "def test(data,tree):\n",
    "    queries = data.iloc[:,1:].to_dict(orient = \"records\")\n",
    "    \n",
    "    predicted = pd.DataFrame(columns=[\"lettr\"]) \n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"lettr\"] = predict(queries[i],tree) \n",
    "    \n",
    "    finalPercent = np.sum(predicted[\"lettr\"]==data[\"lettr\"])/len(data)*100\n",
    "    print('accuracy = ',finalPercent,'%')\n",
    "    return finalPercent\n",
    "\n",
    "def vote(predictions, percents, index):\n",
    "    predList = []\n",
    "    predWeights = []\n",
    "    for i in range(len(percents)):\n",
    "        predList.append(predictions[i].loc[index,\"lettr\"])\n",
    "        predWeights.append(percents[i])\n",
    "    uniqueList = unique(predList)\n",
    "    uniqueCounts = []\n",
    "    uniqueWeights = [0] * len(uniqueList)\n",
    "    for y in predList:\n",
    "        if y in uniqueList:\n",
    "            uniqueWeights[uniqueList.index(y)] += predWeights[predList.index(y)]\n",
    "    \n",
    "    for x in uniqueList:\n",
    "        uniqueCounts.append(predList.count(x))\n",
    "        uniqueWeights[uniqueList.index(x)] /= uniqueCounts[uniqueList.index(x)]\n",
    "        \n",
    "    maxCount = 1\n",
    "    letter = ''\n",
    "    for f in uniqueList:\n",
    "        if uniqueCounts[uniqueList.index(f)] > maxCount:\n",
    "            maxCount = uniqueCounts[uniqueList.index(f)]\n",
    "            letter = f\n",
    "        elif uniqueCounts[uniqueList.index(f)] == maxCount:\n",
    "            letter = ''\n",
    "    if letter != '':\n",
    "        return letter\n",
    "    \n",
    "    maximum = 0\n",
    "    for z in uniqueWeights:\n",
    "        if z > maximum:\n",
    "            maximum = z\n",
    "    return uniqueList[uniqueWeights.index(z)]\n",
    "\n",
    "confusionMatrix = None\n",
    "\n",
    "def tests(data,trees):\n",
    "    queries = data.iloc[:,1:].to_dict(orient = \"records\")\n",
    "    percent = []\n",
    "    predictions = []\n",
    "    predicted = pd.DataFrame(columns=[\"lettr\"])\n",
    "    finalPredicted = pd.DataFrame(columns=[\"lettr\"])\n",
    "    for k in range(len(trees)):\n",
    "        for i in range(len(data)):\n",
    "            predicted.loc[i,\"lettr\"] = predict(queries[i],trees[k])\n",
    "        predictions.append(predicted.copy(deep=True))\n",
    "        percent.append(np.sum(predicted[\"lettr\"]==data[\"lettr\"])/len(data))\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"lettr\"] = vote(predictions, percent, i)\n",
    "        \n",
    "    confusionMatrix = confusion_matrix(data[\"lettr\"], predicted[\"lettr\"])\n",
    "    print(confusionMatrix)\n",
    "    finalPercent = np.sum(predicted[\"lettr\"]==data[\"lettr\"])/len(data)*100\n",
    "    print('accuracy = ',finalPercent,'%')\n",
    "    return finalPercent, confusionMatrix\n",
    "\n",
    "def modeOfBranch(branch,b=False):\n",
    "    track = []\n",
    "    if b:\n",
    "        pp.pprint(branch)\n",
    "    if isinstance(branch,dict):\n",
    "        for value in branch.values():\n",
    "            if isinstance(value,str) and len(value) == 1:\n",
    "                track.append(value)\n",
    "            elif isinstance(value,dict):\n",
    "                track.append(modeOfBranch(value))\n",
    "    if track == []:\n",
    "        return branch\n",
    "    return max(set(track), key=track.count)            \n",
    "\n",
    "#def mode(dataD):\n",
    "#    track={}\n",
    "#    if isinstance(dataD,dict):\n",
    "#        for key, value in dataD.items():\n",
    "#            if isinstance(value,str) and not isinstance(value,dict):\n",
    "#                track[value] = 0\n",
    "#            else:\n",
    "#                track[value] += 1\n",
    "#    temp = {}\n",
    "#    if track != {}:\n",
    "#        temp[key] = max(track, key=track.get)\n",
    "#        for val in temp.values():\n",
    "#            return val\n",
    "\n",
    "#def simplify(tree, data, ogTree, treeU, accuracy = 100):\n",
    "#    \n",
    "#    for key, child in tree.items():\n",
    "#        if isinstance(child, dict):\n",
    "#            tree[key] = simplify(child, data, ogTree[key], tree, test(data,tree))\n",
    "#\n",
    "#    if all(isinstance(child, str) and len(child) == 1 for child in tree.values()):\n",
    "#        for keyU, childU in treeU.items():\n",
    "#            if all(isinstance(childU, str) and len(childU) == 1 for childU in treeU.values()):\n",
    "#                treeU[keyU] = mode(childU)\n",
    "#        if test(data,treeU) <= test(data,ogTree): \n",
    "#            return mode(tree)\n",
    "#\n",
    "#    return tree\n",
    "\n",
    "#def simplifyBranch(branch, tree, OGtree, data):\n",
    "#    for key, child in branch.items():\n",
    "#        if isinstance(child, dict):\n",
    "#            if not all(isinstance(child2, str) for child2 in child.values()):\n",
    "#                branch[key] = simplifyBranch(child, tree, OGtree, data)\n",
    "#            \n",
    "#    branchCopy = cp.deepcopy(branch)\n",
    "#    branch = modeOfBranch(branch,True)\n",
    "#    if test(data, tree) >= test(data,OGtree):\n",
    "#        OGtree = tree\n",
    "#    else:\n",
    "#        branch = branchCopy\n",
    "#def simplify(tree, data):\n",
    "#    pruningTree = cp.deepcopy(tree) #copy of tree to prune\n",
    "#    \n",
    "#    for key, child in pruningTree.items():\n",
    "#        if isinstance(child, dict):\n",
    "#            pruningTree[key] = simplifyBranch(child, pruningTree, tree, data)\n",
    "#            \n",
    "#    return tree\n",
    "    \n",
    "\n",
    "#tree2 = cp.deepcopy(tree)\n",
    "#test(testingData, simplify(tree2, validationData, tree, tree2, test(validationData, tree2)))\n",
    "\n",
    "#pp.pprint(tree)\n",
    "\n",
    "#pp.pprint(tree2)\n",
    "\n",
    "def randomForest(data, splits):\n",
    "    trees = []\n",
    "    splitData = dataSplit(data,splits)\n",
    "    for d in range(splits):\n",
    "        trees.append(ID3(splitData[d],splitData[d],data.columns[1:]))\n",
    "    return trees\n",
    "\n",
    "#trees1 = randomForest(trainingData, 1)\n",
    "\n",
    "#tests(testingData, trees1)\n",
    "\n",
    "#trees10 = randomForest(trainingData, 10)\n",
    "#trees9 = randomForest(trainingData, 9)\n",
    "#trees8 = randomForest(trainingData, 8)\n",
    "#trees7 = randomForest(trainingData, 7)\n",
    "#trees6 = randomForest(trainingData, 6)\n",
    "#trees5 = randomForest(trainingData, 5)\n",
    "#trees4 = randomForest(trainingData, 4)\n",
    "#trees3 = randomForest(trainingData, 3)\n",
    "#trees2 = randomForest(trainingData, 2)\n",
    "\n",
    "#tt = dataset.sample(frac=0.1).reset_index(drop=True)\n",
    "#ttt = tt.sample(frac=0.2)\n",
    "#tt = tt.drop(ttt.index).reset_index(drop=True)\n",
    "#treesC1 = randomForestC(trainingData, 1, 20, 10)\n",
    "#pp.pprint(treesC1[0])\n",
    "#testsC(testingData, treesC1)\n",
    "\n",
    "#tests(testingData, trees10)\n",
    "#tests(testingData, trees9)\n",
    "#tests(testingData, trees8)\n",
    "#tests(testingData, trees7)\n",
    "#tests(testingData, trees6)\n",
    "#tests(testingData, trees5)\n",
    "#tests(testingData, trees4)\n",
    "#tests(testingData, trees3)\n",
    "#tests(testingData, trees2)\n",
    "\n",
    "#trees20 = randomForest(trainingData, 20)\n",
    "#tests(testingData, trees20)\n",
    "#treesC2 = randomForestC(trainingData, 1, 20, 20)\n",
    "#testsC(testingData, treesC2)\n",
    "\n",
    "#treesC3 = randomForestC(trainingData, 1, 20, 30)\n",
    "#testsC(testingData, treesC3)\n",
    "\n",
    "#treesC4 = randomForestC(trainingData, 1, 10, 10)\n",
    "#testsC(testingData, treesC4)\n",
    "\n",
    "#treesMulti = randomForestC(trainingData, 2, 20, 10)\n",
    "#testsC(testingData, treesMulti)\n",
    "\n",
    "#treesMulti2 = randomForestC(trainingData, 5, 20, 10)\n",
    "#testsC(testingData, treesMulti2)\n",
    "\n",
    "#treesC4 = randomForestC(trainingData, 1, 30, 20)\n",
    "#testsC(testingData,treesC4)\n",
    "\n",
    "plotDiscrete = {}\n",
    "plotDiscrete[\"splits\"] = [1,2,5,10,20,30]\n",
    "accuracies = []\n",
    "confusionMatricesD = []\n",
    "for d in plotDiscrete[\"splits\"]:\n",
    "    trees = randomForest(trainingData, d)\n",
    "    testResults = tests(testingData, trees)\n",
    "    accuracies.append(testResults[0])\n",
    "    confusionMatricesD.append(testResults[1])\n",
    "    print(d)\n",
    "plotDiscrete[\"accuracy\"] = accuracies\n",
    "discreteDataFrame = pd.DataFrame(plotDiscrete)\n",
    "discreteDataFrame.plot(kind='bar', x='splits', y='accuracy', ylim=100)\n",
    "plt.savefig(\"Discrete.png\")\n",
    "plt.show()\n",
    "\n",
    "features = [\"splits\", \"maxDepth\", \"minSize\", \"accuracy\"]\n",
    "splits = [1,5,10,20]\n",
    "maxDepths = [10,20,30]\n",
    "minSize = [5,10,20]\n",
    "results = []\n",
    "treesC = []\n",
    "confusionMatricesC = []\n",
    "for s in splits:\n",
    "    for d in maxDepths:\n",
    "        for m in minSize:\n",
    "            trees = randomForestC(trainingData, s, d, m)\n",
    "            treesC.append(trees)\n",
    "            testResults = testsC(testingData, trees)\n",
    "            plot = {}\n",
    "            plot[features[0]] = s\n",
    "            plot[features[1]] = d\n",
    "            plot[features[2]] = m\n",
    "            plot[features[3]] = testResults[0]\n",
    "            confusionMatricesC.append(testResults[1])\n",
    "            results.append(plot)\n",
    "            print(s,d,m, testResults[0])\n",
    "continuousDataFrame = pd.DataFrame(results)\n",
    "print(continuousDataFrame)\n",
    "\n",
    "print(discreteDataFrame)\n",
    "\n",
    "depths2 = [40,50]\n",
    "size2 = [1,5]\n",
    "for s in splits:\n",
    "    for d in depths2:\n",
    "        for m in size2:\n",
    "            trees = randomForestC(trainingData, s, d, m)\n",
    "            treesC.append(trees)\n",
    "            testResults = testsC(testingData, trees)\n",
    "            plot = {}\n",
    "            plot[features[0]] = s\n",
    "            plot[features[1]] = d\n",
    "            plot[features[2]] = m\n",
    "            plot[features[3]] = testResults[0]\n",
    "            confusionMatricesC.append(testResults[1])\n",
    "            results.append(plot)\n",
    "            print(s,d,m, testResults[0])\n",
    "df2 = pd.DataFrame(results)\n",
    "print(df2)\n",
    "\n",
    "depths3 = [25,30,35,45]\n",
    "for s in splits:\n",
    "    for d in depths3:\n",
    "        trees = randomForestC(trainingData, s, d, 1)\n",
    "        treesC.append(trees)\n",
    "        testResults = testsC(testingData, trees)\n",
    "        plot = {}\n",
    "        plot[features[0]] = s\n",
    "        plot[features[1]] = d\n",
    "        plot[features[2]] = m\n",
    "        plot[features[3]] = testResults[0]\n",
    "        confusionMatricesC.append(testResults[1])\n",
    "        results.append(plot)\n",
    "        print(s,d,m, testResults[0])\n",
    "df3 = pd.DataFrame(results)\n",
    "print(df3)\n",
    "\n",
    "print(results[52])\n",
    "\n",
    "for i in range(16):\n",
    "    results[52+i][features[2]] = 1\n",
    "\n",
    "df3 = pd.DataFrame(results)\n",
    "\n",
    "print(df3)\n",
    "\n",
    "from pandas.plotting import table\n",
    "\n",
    "ax = plt.subplot(111, frame_on=False) # no visible frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "table(ax, df3)\n",
    "plt.savefig('continuousTable.png')\n",
    "\n",
    "def plotConfusionMatrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]).replace(\".0\", \"\"),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig(title +\".png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "conf = testsC(testingData,treesC[53])\n",
    "plotConfusionMatrix(conf[1], np.unique(dataset[\"lettr\"]), 'continuousConfusionMatrix')\n",
    "\n",
    "#trees = randomForest(trainingData, 1)\n",
    "testResults = tests(testingData, trees)\n",
    "plotConfusionMatrix(testResults[1], np.unique(dataset[\"lettr\"]))\n",
    "\n",
    "df3.to_html('tableC.html')\n",
    "\n",
    "print(df3.columns)\n",
    "df3 = df3.sort_values('minSize', ascending=True)\n",
    "df4 = df3[:24].reset_index(drop=True).drop('minSize', axis=1)\n",
    "ax = plt.gca()\n",
    "df4 = df4.sort_values('accuracy', ascending=False)\n",
    "#df4 = df4.sort_values('splits', ascending = True)\n",
    "#df4.sort_values('maxDepth', ascending=False).drop_duplicates('A').sort_index()\n",
    "df4 = df4[:6].sort_values('maxDepth')\n",
    "print(df4)\n",
    "df4.plot(kind='bar', x = 'maxDepth', y = 'accuracy', ax=ax)\n",
    "plt.show()\n",
    "\n",
    "df3[:30].reset_index(drop=True).to_html('tableC.html')\n",
    "\n",
    "def label_by_id(v, label, ID):\n",
    "    num = v.get_label_by_id(ID).get_text()\n",
    "    v.get_label_by_id(ID).set_text(label + \"\\n\\n\" + num)\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib_venn\n",
    "def plotVenDiagram(Ab, aB, AB, ab, letter):\n",
    "\n",
    "    # Ab  A and not B\n",
    "    # aB - not A and B\n",
    "    # AB - A and B\n",
    "    # ab - neither A or B \n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    v = venn2(subsets=(Ab, aB, AB), set_labels=('System predicts letter ' + letter, 'Actually letter ' + letter))\n",
    "\n",
    "    label_by_id(v, 'False positives', '01')\n",
    "    label_by_id(v, 'False negatives', '10')\n",
    "    label_by_id(v, 'True positives', '11')\n",
    "\n",
    "    v.get_patch_by_id('01').set_color('green')\n",
    "    v.get_patch_by_id('10').set_color('blue')\n",
    "\n",
    "\n",
    "    plt.figtext(0.1, 0.85, 'True Negatives')\n",
    "    plt.figtext(0.1, 0.8, str(ab))\n",
    "    plt.savefig(letter + '_venn diagram.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "TP = conf[1][7][7]\n",
    "print(TP)\n",
    "FP = 0\n",
    "for i in range(26):\n",
    "    if i != 7:\n",
    "        FP = FP + conf[1][i][7]\n",
    "print(FP)\n",
    "FN = 0\n",
    "for i in range(26):\n",
    "    if i != 7:\n",
    "        FN = FN + conf[1][7][i]\n",
    "print(FN)\n",
    "TN = 4000 - FN - FP - TP\n",
    "plotVenDiagram(FN, FP, TP, TN, 'H')\n",
    "\n",
    "TP = conf[1][6][6]\n",
    "print(TP)\n",
    "FP = 0\n",
    "for i in range(26):\n",
    "    if i != 6:\n",
    "        FP = FP + conf[1][i][6]\n",
    "print(FP)\n",
    "FN = 0\n",
    "for i in range(26):\n",
    "    if i != 6:\n",
    "        FN = FN + conf[1][6][i]\n",
    "print(FN)\n",
    "TN = 4000 - FN - FP - TP\n",
    "plotVenDiagram(FN, FP, TP, TN, 'G')\n",
    "\n",
    "TP = conf[1][15][15]\n",
    "print(TP)\n",
    "FP = 0\n",
    "for i in range(26):\n",
    "    if i != 15:\n",
    "        FP = FP + conf[1][i][15]\n",
    "print(FP)\n",
    "FN = 0\n",
    "for i in range(26):\n",
    "    if i != 15:\n",
    "        FN = FN + conf[1][15][i]\n",
    "print(FN)\n",
    "TN = 4000 - FN - FP - TP\n",
    "plotVenDiagram(FN, FP, TP, TN, 'O')\n",
    "\n",
    "TP = testResults[1][7][7]\n",
    "print(TP)\n",
    "FP = 0\n",
    "for i in range(26):\n",
    "    if i != 7:\n",
    "        FP = FP + testResults[1][i][7]\n",
    "print(FP)\n",
    "FN = 0\n",
    "for i in range(26):\n",
    "    if i != 7:\n",
    "        FN = FN + testResults[1][7][i]\n",
    "print(FN)\n",
    "TN = 4000 - FN - FP - TP\n",
    "plotVenDiagram(FN, FP, TP, TN, 'H')\n",
    "\n",
    "TP = testResults[1][6][6]\n",
    "print(TP)\n",
    "FP = 0\n",
    "for i in range(26):\n",
    "    if i != 6:\n",
    "        FP = FP + testResults[1][i][6]\n",
    "print(FP)\n",
    "FN = 0\n",
    "for i in range(26):\n",
    "    if i != 7:\n",
    "        FN = FN + testResults[1][6][i]\n",
    "print(FN)\n",
    "TN = 4000 - FN - FP - TP\n",
    "plotVenDiagram(FN, FP, TP, TN, 'G')\n",
    "\n",
    "\n",
    "\n",
    "discreteDataFrame.to_html('ds.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
